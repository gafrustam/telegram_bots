"""
OpenAI-based task generation, theory generation, and answer evaluation.
"""

import json
import logging
import re

from openai import AsyncOpenAI

from config import OPENAI_API_KEY, OPENAI_MODEL

logger = logging.getLogger(__name__)
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _extract_json(text: str) -> dict:
    """Extract first JSON object from a string (handles markdown code blocks)."""
    # Strip markdown code fences if present
    text = re.sub(r"```(?:json)?\s*", "", text).strip().rstrip("`").strip()
    # Find first { ... }
    start = text.find("{")
    end = text.rfind("}") + 1
    if start == -1 or end == 0:
        raise ValueError(f"No JSON object found in: {text[:200]}")
    return json.loads(text[start:end])


async def _chat(system: str, user: str, temperature: float = 0.8) -> str:
    response = await client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        temperature=temperature,
    )
    return response.choices[0].message.content.strip()


# ---------------------------------------------------------------------------
# Task generation
# ---------------------------------------------------------------------------

TASK_SYSTEM = (
    "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —É—á–∏—Ç–µ–ª—å –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏, —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –í–ü–† "
    "(–í—Å–µ—Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–æ—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã). "
    "–ó–∞–¥–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã —Ç–æ—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º –¥–µ–º–æ–≤–µ—Ä—Å–∏—è–º –í–ü–†, "
    "–±—ã—Ç—å —á—ë—Ç–∫–∏–º–∏, –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–º–∏ –∏ –∏–º–µ—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —á–∏—Å–ª–æ–≤–æ–π –æ—Ç–≤–µ—Ç. "
    "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π."
)

TASK_USER_TEMPLATE = """
–°–æ–∑–¥–∞–π –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è –í–ü–† –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ.

–ö–ª–∞—Å—Å: {grade}
–ù–æ–º–µ—Ä –∑–∞–¥–∞–Ω–∏—è: {task_num}
–¢–µ–º–∞ –∑–∞–¥–∞–Ω–∏—è: {topic}
–ü–æ–¥—Å–∫–∞–∑–∫–∞ –∫ —Ç–∏–ø—É: {hint}

–í–µ—Ä–Ω–∏ JSON —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "task_text": "–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–¥–∞–Ω–∏—è –¥–ª—è —É—á–µ–Ω–∏–∫–∞ (–±–µ–∑ –æ—Ç–≤–µ—Ç–∞)",
  "correct_answer": "–¢–æ—á–Ω—ã–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (—á–∏—Å–ª–æ, –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –∫—Ä–∞—Ç–∫–∞—è —Ñ—Ä–∞–∑–∞)",
  "solution": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ/–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤ 2‚Äì4 —Å—Ç—Ä–æ–∫–∏"
}}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ß–∏—Å–ª–∞ –∏ —É—Å–ª–æ–≤–∏—è –∑–∞–¥–∞—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏
- –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–º
- –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –í–ü–†
- –ò—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑–Ω—ã–µ —á–∏—Å–ª–∞ –∫–∞–∂–¥—ã–π —Ä–∞–∑ (—ç—Ç–æ –≤–∞–∂–Ω–æ!)
"""


async def generate_task(grade: int, task_num: int, topic: str, hint: str) -> dict:
    """
    Returns dict with keys: task_text, correct_answer, solution
    """
    user_prompt = TASK_USER_TEMPLATE.format(
        grade=grade, task_num=task_num, topic=topic, hint=hint
    )
    for attempt in range(3):
        try:
            raw = await _chat(TASK_SYSTEM, user_prompt)
            data = _extract_json(raw)
            if all(k in data for k in ("task_text", "correct_answer", "solution")):
                return data
        except Exception as e:
            logger.warning("generate_task attempt %d failed: %s", attempt + 1, e)
    raise RuntimeError("Failed to generate task after 3 attempts")


# ---------------------------------------------------------------------------
# Theory generation
# ---------------------------------------------------------------------------

THEORY_SYSTEM = (
    "–¢—ã ‚Äî —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤. "
    "–û–±—ä—è—Å–Ω—è–π –º–∞—Ç–µ—Ä–∏–∞–ª —è—Å–Ω–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏. "
    "–ò—Å–ø–æ–ª—å–∑—É–π —è–∑—ã–∫, –ø–æ–Ω—è—Ç–Ω—ã–π —É—á–µ–Ω–∏–∫—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª–∞—Å—Å–∞."
)

THEORY_USER_TEMPLATE = """
–û–±—ä—è—Å–Ω–∏ —Ç–µ–æ—Ä–∏—é –¥–ª—è –∑–∞–¥–∞–Ω–∏—è –í–ü–† –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ.

–ö–ª–∞—Å—Å: {grade}
–ù–æ–º–µ—Ä –∑–∞–¥–∞–Ω–∏—è –≤ –í–ü–†: {task_num}
–¢–µ–º–∞: {topic}
–ü–æ–¥—Å–∫–∞–∑–∫–∞: {hint}

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–π Markdown-–ø–æ–¥–æ–±–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Telegram HTML):
1. <b>üìñ –ö–ª—é—á–µ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è</b> ‚Äî –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
2. <b>üìê –§–æ—Ä–º—É–ª—ã –∏ –ø—Ä–∞–≤–∏–ª–∞</b> ‚Äî –≤—Å–µ –Ω—É–∂–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã
3. <b>ü™ú –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—à–µ–Ω–∏—è</b> ‚Äî –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω
4. <b>‚úèÔ∏è –†–∞–∑–æ–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä</b> ‚Äî —Ç–∏–ø–∏—á–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ —Å –ø–æ–ª–Ω—ã–º —Ä–µ—à–µ–Ω–∏–µ–º
5. <b>‚ö†Ô∏è –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏</b> ‚Äî –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ

–ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –Ω–æ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–º (–Ω–µ –±–æ–ª–µ–µ 600 —Å–ª–æ–≤).
"""


async def generate_theory(grade: int, task_num: int, topic: str, hint: str) -> str:
    user_prompt = THEORY_USER_TEMPLATE.format(
        grade=grade, task_num=task_num, topic=topic, hint=hint
    )
    return await _chat(THEORY_SYSTEM, user_prompt, temperature=0.5)


# ---------------------------------------------------------------------------
# Answer evaluation
# ---------------------------------------------------------------------------

EVAL_SYSTEM = (
    "–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π, –Ω–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–π —É—á–∏—Ç–µ–ª—å –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏. "
    "–û—Ü–µ–Ω–∏–≤–∞–π –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ. "
    "–ó–∞—Å—á–∏—Ç—ã–≤–∞–π —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–µ —Ñ–æ—Ä–º—ã –æ—Ç–≤–µ—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2.5 –∏ 5/2, –∏–ª–∏ '—Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ ABC' –∏ 'ABC'). "
    "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π."
)

EVAL_USER_TEMPLATE = """
–û—Ü–µ–Ω–∏ –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞ –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ –í–ü–† –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ.

–ó–∞–¥–∞–Ω–∏–µ: {task_text}
–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {correct_answer}
–û—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞: {user_answer}
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª –∑–∞ –∑–∞–¥–∞–Ω–∏–µ: {max_points}

–í–µ—Ä–Ω–∏ JSON —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "points": <—á–∏—Å–ª–æ –æ—Ç 0 –¥–æ {max_points}>,
  "is_correct": <true –∏–ª–∏ false>,
  "verdict": "<–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞: '–í–µ—Ä–Ω–æ ‚úÖ', '–ß–∞—Å—Ç–∏—á–Ω–æ –≤–µ—Ä–Ω–æ ‚ö†Ô∏è' –∏–ª–∏ '–ù–µ–≤–µ—Ä–Ω–æ ‚ùå'>",
  "explanation": "<2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –ø–æ—á–µ–º—É –æ—Ç–≤–µ—Ç –≤–µ—Ä–µ–Ω/–Ω–µ–≤–µ—Ä–µ–Ω –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ>"
}}
"""


async def evaluate_answer(
    task_text: str,
    correct_answer: str,
    user_answer: str,
    max_points: int,
) -> dict:
    """
    Returns dict: points, is_correct, verdict, explanation
    """
    user_prompt = EVAL_USER_TEMPLATE.format(
        task_text=task_text,
        correct_answer=correct_answer,
        user_answer=user_answer,
        max_points=max_points,
    )
    for attempt in range(3):
        try:
            raw = await _chat(EVAL_SYSTEM, user_prompt, temperature=0.2)
            data = _extract_json(raw)
            if "points" in data and "is_correct" in data:
                data["points"] = min(int(data["points"]), max_points)
                return data
        except Exception as e:
            logger.warning("evaluate_answer attempt %d failed: %s", attempt + 1, e)
    # Fallback: manual comparison
    norm_correct = correct_answer.strip().lower()
    norm_user = user_answer.strip().lower()
    is_correct = norm_correct == norm_user
    return {
        "points": max_points if is_correct else 0,
        "is_correct": is_correct,
        "verdict": "–í–µ—Ä–Ω–æ ‚úÖ" if is_correct else "–ù–µ–≤–µ—Ä–Ω–æ ‚ùå",
        "explanation": f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {correct_answer}",
    }


# ---------------------------------------------------------------------------
# Batch evaluation (used in test mode)
# ---------------------------------------------------------------------------

async def evaluate_all_answers(tasks: list[dict]) -> list[dict]:
    """
    tasks: list of dicts with keys: task_text, correct_answer, user_answer, max_points
    Returns same list with added keys: points, is_correct, verdict, explanation
    """
    import asyncio

    async def eval_one(t: dict) -> dict:
        result = await evaluate_answer(
            t["task_text"], t["correct_answer"], t["user_answer"], t["max_points"]
        )
        return {**t, **result}

    return await asyncio.gather(*[eval_one(t) for t in tasks])
